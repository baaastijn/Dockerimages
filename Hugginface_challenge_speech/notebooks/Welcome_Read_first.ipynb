{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3082c664",
   "metadata": {},
   "source": [
    "# Welcome to Speech recognition community week - version 2\n",
    "![toto](https://huggingface.co/front/assets/huggingface_logo-noborder.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05907dc",
   "metadata": {},
   "source": [
    "## HuggingFace challenge informations\n",
    "You will be able to find challenge informations, important dates and getting started on <https://discuss.huggingface.co/>.\n",
    "\n",
    "Discord channel for this event is available on <http://hf.co/join/discord>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62a7043",
   "metadata": {},
   "source": [
    "## OVHcloud infrastructure informations\n",
    "OVHcloud is a european cloud provider who's joining forces with HuggingFace for this challenge.\n",
    "\n",
    "If you read these lines, we are happy to count you as a competitor using our AI tools!\n",
    "\n",
    "\n",
    "### OVHcloud AI tools concepts\n",
    "\n",
    "OVHcloud provides managed **AI Notebooks** (Jupyter and VSCode), **AI Training** and **AI Apps** (high-availability deployments).\n",
    "\n",
    "All of them can be powered by CPUs (from 1 to 12) or NVIDIA GPUs (1 to 4) like V100S 32GB.\n",
    "\n",
    "This enviroment is currently hosted on AI Training with a specific Docker image (see after).\n",
    "\n",
    "We can represent AI Tools concept like this:\n",
    "\n",
    "![AI Tools](https://i.imgur.com/7p5QJUi.png)\n",
    "\n",
    "\n",
    "### About this Jupyter notebook environment\n",
    "\n",
    "For this challenge we decided to craft a specific Docker image with preinstalled Python libraries.\n",
    "\n",
    "The Dockerfile can be found on <https://github.com/baaastijn/Dockerimages>.\n",
    "\n",
    "As explained in the Dockerfile, we start from an OVHcloud image containing Jupyter, CUDA drivers and PyTorch.\n",
    "them we install transformers, datasets, librosa, jiwer and few other libraries.\n",
    "\n",
    "Transformers and datasets are installed from git sources to get the latest hotfixes.\n",
    "\n",
    "This Docker image is hosted in public registry, on <https://hub.docker.com/r/baaastijn/ovh_huggingface/>\n",
    "\n",
    "Feel free to work without this image if you prefer your own environment.\n",
    "\n",
    "\n",
    "### Working efficiently with AI Training and data\n",
    "\n",
    "OVHcloud AI Tools can be managed through a **UI** (OVHcloud Control panel) or the  **ovhai CLI** ([installation instructions](https://docs.ovh.com/gb/en/ai-training/install-client/).\n",
    "\n",
    "When you start a new AI Notebook, AI Training or Apps, you will have:\n",
    "\n",
    "- **A local and ephemeral storage**: each GPU is provided with 750GiB local SSD NVMe storage (/workspace).\n",
    "- **Ability to attach and sync remote storage containers**: you can put you data in OVHcloud Object Storage, then during the job creation, sync this data. The data will be mounted as volumes, in read-only or read-write. \n",
    "\n",
    "**We strongly recommend to:**\n",
    " \n",
    "- Attach a first Object Storage container who will take your datasets inputs, in read-only and cache activated (so it can be used by multiple jobs in parralel).\n",
    "- Attach a second Object Storage container for your results, in read-write.\n",
    "- Both Object Storage containers should be in the same region as your GPU (GRA, france or BHS, Canada).\n",
    " \n",
    "Why ? because by doing this you will be able **to launch multiple jobs on the same data sources** , giving you more performance and flexibility.\n",
    "We provide some caching features especially useful when dealing with large amount of data.\n",
    " \n",
    "Also, you will **not lose you data when you stop your job**.\n",
    " \n",
    "Example with the CLI to start a job with 2 x Object sotrage containers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0442deea",
   "metadata": {},
   "source": [
    " ```bash\n",
    " # Upload a local folder to OVHcloud Storage (if container doesn't exist, we will create it)\n",
    " ovhai data copy some/local-folder/ datasets@GRA:some-prefix/\n",
    " \n",
    " # Run a new job with 1 GPU and provided Docker image\n",
    " ovhai job run \\\n",
    "\t--name ovh_huggingface-job-name \\\n",
    "\t--flavor ai1-1-gpu \\\n",
    "\t--gpu 1 \\\n",
    "\t--volume datasets@GRA/:/workspace/my_data:RO:cache \\\n",
    "\t--volume outputs@GRA/:/workspace/output_data:RW \\\n",
    "\tbaaastijn/ovh_huggingface:latest\n",
    " \n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb02f757",
   "metadata": {},
   "source": [
    "We do hope that you enjoy this Speech Recognition community week !\n",
    "\n",
    "OVHcloud Team x HuggingFace Team"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
